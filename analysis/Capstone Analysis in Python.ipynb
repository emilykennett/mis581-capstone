{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2a98b-e1ce-4065-af82-fbc6ad98b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, roc_curve, RocCurveDisplay,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "\n",
    "# File paths\n",
    "REPO_ROOT = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path(\".\").resolve()\n",
    "DATA_DIR  = REPO_ROOT / \"data\"\n",
    "DEMO_DIR  = DATA_DIR / \"demo\"\n",
    "OUT_FIG   = REPO_ROOT / \"outputs\" / \"figures\"\n",
    "OUT_TAB   = REPO_ROOT / \"outputs\" / \"tables\"\n",
    "OUT_MOD   = REPO_ROOT / \"outputs\" / \"models\"\n",
    "for d in (OUT_FIG, OUT_TAB, OUT_MOD):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Brand colors\n",
    "MA_RED  = \"#E31837\"\n",
    "MA_GRAY = \"#717073\"\n",
    "MA_BLACK = \"#231F20\"\n",
    "MA_TEAL  = \"#00728F\"\n",
    "\n",
    "\n",
    "# Helpers\n",
    "def to01(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\",\"yes\",\"y\",\"true\",\"t\"}: return 1\n",
    "    if s in {\"0\",\"no\",\"n\",\"false\",\"f\"}: return 0\n",
    "    try:\n",
    "        return 1 if float(s) != 0.0 else 0\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def safe_read_csv(filename: str, demo_name: str | None = None, required: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Read from data/, else data/demo/ if provided.\"\"\"\n",
    "    real_p = DATA_DIR / filename\n",
    "    if real_p.exists():\n",
    "        return pd.read_csv(real_p, low_memory=False)\n",
    "    if demo_name:\n",
    "        demo_p = DEMO_DIR / demo_name\n",
    "        if demo_p.exists():\n",
    "            print(f\"[info] Using demo file for {filename}: {demo_p.name}\")\n",
    "            return pd.read_csv(demo_p, low_memory=False)\n",
    "    if required:\n",
    "        raise FileNotFoundError(f\"Missing required data file: {filename}\")\n",
    "    print(f\"[warn] Optional data missing (and no demo): {filename}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def nonempty_series(x):\n",
    "    return x.astype(str).str.strip().replace({\"nan\":\"\", \"<na>\":\"\"})\n",
    "\n",
    "SPORT_MAP = {\n",
    "    0: \"None\", 1: \"Basketball\", 2: \"Cross Country\", 3: \"Football\",\n",
    "    4: \"Soccer\", 5: \"Track & Field\", 6: \"Volleyball\",\n",
    "    7: \"Other (College Participation)\", 8: \"Alpine Ski\", 9: \"Lacrosse\",\n",
    "    10: \"Other (No College Participation)\"\n",
    "}\n",
    "\n",
    "\n",
    "# Load (demo-safe)\n",
    "ma_bench = safe_read_csv(\"FOR ANALYSIS - MA Benchmark.csv\",  \"synthetic_benchmark.csv\", required=True)\n",
    "ma_pred  = safe_read_csv(\"FOR ANALYSIS - MA Predictive.csv\", \"synthetic_predictive.csv\", required=True)\n",
    "ncaa     = safe_read_csv(\"FOR ANALYSIS - NCAA.csv\",          \"synthetic_ncaa.csv\", required=False)\n",
    "nfhs     = safe_read_csv(\"FOR ANALYSIS - NFHS.csv\",          \"synthetic_nfhs.csv\", required=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eab7c0-c531-48cf-8266-9a3ead7aec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ1 — Overall chi-square vs NCAA (6.3%)\n",
    "def filter_cohort_no_ma_grad_nan(df, grad_col=\"MA_Graduate\"):\n",
    "    if grad_col not in df.columns:\n",
    "        return df.copy()\n",
    "    grad = df[grad_col].map(to01)\n",
    "    return df[grad.notna()].copy()\n",
    "\n",
    "def add_college_athlete_flag(frame):\n",
    "    t = frame.copy()\n",
    "    t[\"college_athlete\"] = t[\"College_Athletics_Participant\"].map(to01)\n",
    "    if \"College_NCAA_Division\" in t.columns:\n",
    "        has_div = nonempty_series(t[\"College_NCAA_Division\"]) != \"\"\n",
    "        m = t[\"college_athlete\"].isna()\n",
    "        t.loc[m, \"college_athlete\"] = has_div.loc[m].astype(int)\n",
    "    t[\"college_athlete\"] = t[\"college_athlete\"].fillna(0).astype(int)\n",
    "    return t\n",
    "\n",
    "bench = add_college_athlete_flag(filter_cohort_no_ma_grad_nan(ma_bench, \"MA_Graduate\"))\n",
    "obs_adv   = int(bench[\"college_athlete\"].sum())\n",
    "obs_total = int(len(bench))\n",
    "obs_non   = obs_total - obs_adv\n",
    "\n",
    "NCAA_BASE = 0.063\n",
    "exp_adv = obs_total * NCAA_BASE\n",
    "exp_non = obs_total * (1 - NCAA_BASE)\n",
    "chi2, p = stats.chisquare(f_obs=[obs_adv, obs_non], f_exp=[exp_adv, exp_non])\n",
    "\n",
    "(pd.DataFrame({\n",
    "    \"Advanced\":[obs_adv], \"Not_Advanced\":[obs_non], \"N\":[obs_total],\n",
    "    \"Expected_Adv\":[round(exp_adv,2)], \"Expected_Not\":[round(exp_non,2)],\n",
    "    \"Chi2\":[round(chi2,2)], \"p_value\":[p]\n",
    "})\n",
    " .to_csv(OUT_TAB / \"rq1_overall_chi_square.csv\", index=False))\n",
    "\n",
    "# Figure: Observed vs Expected\n",
    "fig, ax = plt.subplots(figsize=(7.5,5.5))\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Observed (MA)\": [obs_adv, obs_non],\n",
    "    \"Expected (NCAA)\": [exp_adv, exp_non]\n",
    "}, index=[\"Advanced\",\"Not Advanced\"])\n",
    "df_plot.plot(kind=\"bar\", ax=ax, color=[MA_RED, MA_GRAY], width=0.75, edgecolor=\"black\")\n",
    "ax.set_title(\"Observed vs Expected Advancement (Overall)\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Count\"); ax.set_xlabel(\"\")\n",
    "ax.legend(loc=\"upper left\"); ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "for pch in ax.patches:\n",
    "    h = pch.get_height()\n",
    "    if np.isfinite(h):\n",
    "        ax.annotate(f\"{h:,.0f}\", (pch.get_x()+pch.get_width()/2, h),\n",
    "                    ha=\"center\", va=\"bottom\", fontsize=9, xytext=(0,3), textcoords=\"offset points\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUT_FIG / \"rq1_overall_observed_vs_expected.png\", dpi=150)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc681ac-944f-464e-9f27-3177b432b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ1 — Per-sport + z-tests\n",
    "def build_hs_participation(ma_pred_df: pd.DataFrame, id_col=\"Identifier\") -> pd.DataFrame:\n",
    "    df = filter_cohort_no_ma_grad_nan(ma_pred_df, \"MA_Graduate\")\n",
    "    sport_cols = [c for c in df.columns if \"sport_code\" in c.lower() and \"college\" not in c.lower()]\n",
    "    long = df[[id_col, *sport_cols]].melt(id_vars=[id_col], value_vars=sport_cols,\n",
    "                                          var_name=\"season\", value_name=\"Sport_Code\")\n",
    "    long[\"Sport_Code\"] = pd.to_numeric(long[\"Sport_Code\"], errors=\"coerce\")\n",
    "    long[\"Sport\"] = long[\"Sport_Code\"].map(SPORT_MAP)\n",
    "    long = long[long[\"Sport\"].notna() & (long[\"Sport\"] != \"None\")]\n",
    "    hs_counts = (long.drop_duplicates([id_col,\"Sport\"])\n",
    "                      .groupby(\"Sport\", as_index=False)\n",
    "                      .agg(MA_HS_Participants=(id_col,\"nunique\")))\n",
    "    return hs_counts\n",
    "\n",
    "def build_college_advancements(ma_pred_df: pd.DataFrame, id_col=\"Identifier\") -> pd.DataFrame:\n",
    "    df = add_college_athlete_flag(filter_cohort_no_ma_grad_nan(ma_pred_df, \"MA_Graduate\"))\n",
    "    df[\"Sport_Code\"] = pd.to_numeric(df.get(\"College_Sport_Code_1\"), errors=\"coerce\")\n",
    "    df[\"Sport\"] = df[\"Sport_Code\"].map(SPORT_MAP)\n",
    "    adv = (df[(df[\"college_athlete\"] == 1) & df[\"Sport\"].notna() & (df[\"Sport\"] != \"None\")]\n",
    "             [[id_col,\"Sport\"]]\n",
    "             .drop_duplicates())\n",
    "    return adv.groupby(\"Sport\", as_index=False).agg(Advanced=(id_col,\"nunique\"))\n",
    "\n",
    "def load_ncaa_rates_clean(ncaa_df: pd.DataFrame, combine_genders=True) -> pd.DataFrame:\n",
    "    if ncaa_df.empty:\n",
    "        return pd.DataFrame(columns=[\"Sport\",\"NCAA_Rate\"])\n",
    "    rates = ncaa_df.copy()\n",
    "    # Expect columns: Sport_Code, HS_Participants_2022_23, Pct_HS_to_NCAA_Overall\n",
    "    rates[\"Sport_Code\"] = pd.to_numeric(rates[\"Sport_Code\"], errors=\"coerce\")\n",
    "    rates[\"HS_Participants_2022_23\"] = (\n",
    "        rates[\"HS_Participants_2022_23\"].astype(str).str.replace(\",\",\"\", regex=False)\n",
    "    ).astype(float)\n",
    "    col = \"Pct_HS_to_NCAA_Overall\"\n",
    "    rates[col] = (rates[col].astype(str).str.replace(\"%\",\"\", regex=False)\n",
    "                  .str.replace(\",\",\"\", regex=False)).astype(float) / 100.0\n",
    "    if combine_genders and \"Gender\" in rates.columns:\n",
    "        tmp = rates.dropna(subset=[\"Sport_Code\",\"HS_Participants_2022_23\",col]).copy()\n",
    "        tmp[\"w\"] = tmp[\"HS_Participants_2022_23\"] * tmp[col]\n",
    "        agg = (tmp.groupby(\"Sport_Code\", as_index=False)\n",
    "                  .agg(w_sum=(\"w\",\"sum\"), hs_sum=(\"HS_Participants_2022_23\",\"sum\")))\n",
    "        agg[\"NCAA_Rate\"] = np.where(agg[\"hs_sum\"]>0, agg[\"w_sum\"]/agg[\"hs_sum\"], np.nan)\n",
    "        out = agg[[\"Sport_Code\",\"NCAA_Rate\"]]\n",
    "    else:\n",
    "        out = rates.rename(columns={col:\"NCAA_Rate\"})[[\"Sport_Code\",\"NCAA_Rate\"]]\n",
    "    out[\"Sport\"] = out[\"Sport_Code\"].map(SPORT_MAP)\n",
    "    return out.dropna(subset=[\"Sport\",\"NCAA_Rate\"])[[\"Sport\",\"NCAA_Rate\"]]\n",
    "\n",
    "hs_counts = build_hs_participation(ma_pred)\n",
    "adv_counts = build_college_advancements(ma_pred)\n",
    "ncaa_rates = load_ncaa_rates_clean(ncaa, combine_genders=True)\n",
    "\n",
    "sport_df = (hs_counts.merge(adv_counts, on=\"Sport\", how=\"left\")\n",
    "                     .merge(ncaa_rates, on=\"Sport\", how=\"left\"))\n",
    "sport_df[\"Advanced\"] = sport_df[\"Advanced\"].fillna(0).astype(int)\n",
    "sport_df = sport_df.dropna(subset=[\"NCAA_Rate\"])\n",
    "sport_df[\"MA_Rate\"] = np.where(sport_df[\"MA_HS_Participants\"]>0,\n",
    "                               sport_df[\"Advanced\"] / sport_df[\"MA_HS_Participants\"], np.nan)\n",
    "\n",
    "# Per-sport z-test table\n",
    "rows = []\n",
    "for _, r in sport_df.iterrows():\n",
    "    n = int(r[\"MA_HS_Participants\"]); x = int(r[\"Advanced\"]); p0 = float(r[\"NCAA_Rate\"])\n",
    "    if n <= 0 or not (0 < p0 < 1): continue\n",
    "    phat = x / n\n",
    "    se = np.sqrt(p0 * (1 - p0) / n)\n",
    "    z = (phat - p0) / se\n",
    "    pval = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    rows.append({\n",
    "        \"Sport\": r[\"Sport\"],\n",
    "        \"MA_HS_Participants\": n,\n",
    "        \"Advanced\": x,\n",
    "        \"MA_Rate\": phat,\n",
    "        \"NCAA_Rate\": p0,\n",
    "        \"z\": z, \"p_value\": pval,\n",
    "        \"Significant_(p<.05)\": \"Yes\" if pval < 0.05 else \"No\"\n",
    "    })\n",
    "\n",
    "z_table = pd.DataFrame(rows).sort_values(\"p_value\") if rows else pd.DataFrame()\n",
    "if not z_table.empty:\n",
    "    z_out = z_table.copy()\n",
    "    z_out[\"MA_Rate\"]   = (z_out[\"MA_Rate\"]*100).round(1)\n",
    "    z_out[\"NCAA_Rate\"] = (z_out[\"NCAA_Rate\"]*100).round(1)\n",
    "    z_out.to_csv(OUT_TAB / \"rq1_per_sport_ztests.csv\", index=False)\n",
    "\n",
    "# Basketball + football bar charts\n",
    "def plot_sport_rate_bar(sport_name: str, out_png: str):\n",
    "    row = sport_df.loc[sport_df[\"Sport\"] == sport_name]\n",
    "    if row.empty: \n",
    "        print(f\"[warn] No data for sport: {sport_name}\"); \n",
    "        return\n",
    "    ma_rate = float(row[\"MA_Rate\"].iloc[0]) * 100.0\n",
    "    ncaa_rt = float(row[\"NCAA_Rate\"].iloc[0]) * 100.0\n",
    "    plt.figure(figsize=(5.5,5))\n",
    "    plt.bar([\"Minnehaha Academy\",\"NCAA Average\"], [ma_rate, ncaa_rt],\n",
    "            color=[MA_RED, MA_GRAY], edgecolor=\"black\")\n",
    "    plt.ylabel(\"Advancement Rate (%)\")\n",
    "    plt.title(f\"{sport_name}: MA vs NCAA\")\n",
    "    plt.ylim(0, max(ma_rate, ncaa_rt)*1.25 if np.isfinite(ma_rate) and np.isfinite(ncaa_rt) else 20)\n",
    "    for i, v in enumerate([ma_rate, ncaa_rt]):\n",
    "        if np.isfinite(v):\n",
    "            plt.text(i, v+0.5, f\"{v:.1f}%\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / out_png, dpi=150); plt.close()\n",
    "\n",
    "for sp, fn in [(\"Basketball\",\"rq1_bar_basketball.png\"),\n",
    "               (\"Football\",\"rq1_bar_football.png\")]:\n",
    "    plot_sport_rate_bar(sp, fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2923744-ce32-4dcd-8bd6-3568db53e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ2 — Logistic regression (odds ratios) + Decision Tree\n",
    "def build_rq2_frame(ma_pred_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = ma_pred_df.copy()\n",
    "    # target with NCAA division fallback\n",
    "    df[\"college_athlete\"] = df[\"College_Athletics_Participant\"].map(to01)\n",
    "    if \"College_NCAA_Division\" in df.columns:\n",
    "        has_div = nonempty_series(df[\"College_NCAA_Division\"]) != \"\"\n",
    "        m = df[\"college_athlete\"].isna()\n",
    "        df.loc[m, \"college_athlete\"] = has_div.loc[m].astype(int)\n",
    "\n",
    "    df[\"gpa\"]          = pd.to_numeric(df.get(\"Cumulative_GPA\"), errors=\"coerce\")\n",
    "    df[\"sports_count\"] = pd.to_numeric(df.get(\"Total_Count_of_HS_Sports_All_Years\"), errors=\"coerce\")\n",
    "    df[\"fine_arts\"]    = (pd.to_numeric(df.get(\"Years_As_Fine_Arts\"), errors=\"coerce\").fillna(0) > 0).astype(int)\n",
    "    df[\"ma_graduate\"]  = df.get(\"MA_Graduate\").map(to01)\n",
    "    df[\"fin_aid\"]      = df.get(\"MA_Financial_Aid\").map(to01)\n",
    "    df[\"free_lunch\"]   = df.get(\"Federal_Free_Lunch\").map(to01)\n",
    "\n",
    "    days_enrolled = pd.to_numeric(df.get(\"Total_Days_Enrolled_MA_All_Years\"), errors=\"coerce\")\n",
    "    tardies       = pd.to_numeric(df.get(\"Total_Number_Tardies_All_Years\"), errors=\"coerce\")\n",
    "    abs_pct       = pd.to_numeric(df.get(\"Percentage_of_Absences_All_Years\"), errors=\"coerce\")\n",
    "    df[\"abs_percent\"] = np.where(abs_pct > 1, abs_pct/100.0, abs_pct)\n",
    "    df[\"tardy_rate\"]  = np.where(days_enrolled.fillna(0)>0, tardies / days_enrolled, np.nan)\n",
    "\n",
    "    df[\"gender\"] = df.get(\"Gender\").astype(\"object\")\n",
    "    df[\"region\"] = df.get(\"Region_City_Based\").astype(\"object\")\n",
    "    df[\"race\"]   = df.get(\"Reported_Federal_Race\").astype(\"object\")\n",
    "\n",
    "    cols = [\"college_athlete\",\"gpa\",\"sports_count\",\"fine_arts\",\"ma_graduate\",\n",
    "            \"abs_percent\",\"tardy_rate\",\"fin_aid\",\"free_lunch\",\n",
    "            \"gender\",\"region\",\"race\"]\n",
    "    dfm = df[cols].copy()\n",
    "    dfm = dfm.dropna(subset=[\"college_athlete\",\"gpa\",\"sports_count\",\"abs_percent\",\"tardy_rate\"])\n",
    "    dfm[\"college_athlete\"] = dfm[\"college_athlete\"].astype(int)\n",
    "    return dfm\n",
    "\n",
    "rq2 = build_rq2_frame(ma_pred)\n",
    "\n",
    "# Split\n",
    "train_df, test_df = train_test_split(rq2, test_size=0.20, random_state=123, stratify=rq2[\"college_athlete\"])\n",
    "\n",
    "# --- Statsmodels logit for ORs ---\n",
    "num_cols = [\"gpa\",\"sports_count\",\"fine_arts\",\"ma_graduate\",\"abs_percent\",\"tardy_rate\",\"fin_aid\",\"free_lunch\"]\n",
    "cat_cols = [\"gender\",\"region\",\"race\"]\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "ct  = ColumnTransformer([(\"num\",\"passthrough\", num_cols), (\"cat\", ohe, cat_cols)], remainder=\"drop\")\n",
    "\n",
    "Xtr = ct.fit_transform(train_df.drop(columns=[\"college_athlete\"]))\n",
    "Xte = ct.transform(test_df.drop(columns=[\"college_athlete\"]))\n",
    "ytr = train_df[\"college_athlete\"].values\n",
    "yte = test_df[\"college_athlete\"].values\n",
    "\n",
    "Xtr_sm = sm.add_constant(Xtr)\n",
    "Xte_sm = sm.add_constant(Xte)\n",
    "\n",
    "logit_model = sm.Logit(ytr, Xtr_sm, missing=\"raise\")\n",
    "logit_res   = logit_model.fit(disp=False)\n",
    "\n",
    "# OR table\n",
    "feature_names = num_cols + list(ct.named_transformers_[\"cat\"].get_feature_names_out(cat_cols))\n",
    "or_df = pd.DataFrame({\n",
    "    \"term\": [\"Intercept\"] + feature_names,\n",
    "    \"odds_ratio\": np.exp(logit_res.params),\n",
    "    \"ci_low\": np.exp(logit_res.conf_int()[0]),\n",
    "    \"ci_high\": np.exp(logit_res.conf_int()[1]),\n",
    "    \"p_value\": logit_res.pvalues\n",
    "})\n",
    "or_df.to_csv(OUT_TAB / \"rq2_logit_odds_ratios.csv\", index=False)\n",
    "\n",
    "# Test metrics + ROC (logit)\n",
    "prob_glm = logit_res.predict(Xte_sm)\n",
    "pred_glm = (prob_glm >= 0.5).astype(int)\n",
    "acc_glm  = accuracy_score(yte, pred_glm)\n",
    "auc_glm  = roc_auc_score(yte, prob_glm)\n",
    "cm_glm   = confusion_matrix(yte, pred_glm)\n",
    "\n",
    "pd.DataFrame([{\"model\":\"logit\",\"accuracy\":acc_glm,\"auc\":auc_glm,\"n_train\":len(ytr),\"n_test\":len(yte)}]) \\\n",
    "  .to_csv(OUT_TAB / \"rq2_logit_metrics.csv\", index=False)\n",
    "pd.DataFrame(cm_glm, index=[\"Actual 0\",\"Actual 1\"], columns=[\"Pred 0\",\"Pred 1\"]) \\\n",
    "  .to_csv(OUT_TAB / \"rq2_logit_confusion_matrix.csv\")\n",
    "\n",
    "fpr, tpr, _ = roc_curve(yte, prob_glm)\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr, lw=2, label=f\"Logit (AUC={auc_glm:.3f})\", color=MA_TEAL)\n",
    "plt.plot([0,1],[0,1],\"--\", color=\"grey\")\n",
    "plt.xlabel(\"1 - Specificity\"); plt.ylabel(\"Sensitivity\")\n",
    "plt.title(\"ROC — Logistic Regression (Test Set)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout(); plt.savefig(OUT_FIG / \"rq2_logit_roc.png\", dpi=150); plt.close()\n",
    "\n",
    "# --- Decision Tree\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "])\n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"clf\", tree)])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid={\"clf__max_depth\":[3,4,5], \"clf__min_samples_leaf\":[10,15,20], \"clf__class_weight\":[None,\"balanced\"]},\n",
    "    cv=5, scoring=\"roc_auc\", n_jobs=-1\n",
    ").fit(train_df.drop(columns=[\"college_athlete\"]), ytr)\n",
    "\n",
    "best = grid.best_estimator_\n",
    "prob_tree = best.predict_proba(test_df.drop(columns=[\"college_athlete\"]))[:,1]\n",
    "auc_tree  = roc_auc_score(yte, prob_tree)\n",
    "yhat_tree = (prob_tree >= 0.5).astype(int)\n",
    "pd.DataFrame(confusion_matrix(yte, yhat_tree), index=[\"Actual 0\",\"Actual 1\"], columns=[\"Pred 0\",\"Pred 1\"]) \\\n",
    "  .to_csv(OUT_TAB / \"rq2_tree_confusion_matrix.csv\")\n",
    "pd.DataFrame([{\"model\":\"decision_tree\",\"auc\":auc_tree}]).to_csv(OUT_TAB / \"rq2_tree_metrics.csv\", index=False)\n",
    "\n",
    "# Tree figure + text rules\n",
    "prep = best.named_steps[\"prep\"]\n",
    "ohe_names = []\n",
    "for name, trans, cols in prep.transformers_:\n",
    "    if name == \"num\":\n",
    "        num_names = cols\n",
    "    elif name == \"cat\":\n",
    "        ohe_names = list(trans.named_steps[\"ohe\"].get_feature_names_out(cols))\n",
    "feat_names = list(num_cols) + ohe_names\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plot_tree(best.named_steps[\"clf\"], feature_names=feat_names, class_names=[\"No\",\"Yes\"], filled=False)\n",
    "plt.tight_layout(); plt.savefig(OUT_FIG / \"rq2_decision_tree.png\", dpi=150); plt.close()\n",
    "\n",
    "rules_txt = export_text(best.named_steps[\"clf\"], feature_names=feat_names)\n",
    "(OUT_MOD / \"rq2_tree_rules.txt\").write_text(rules_txt)\n",
    "\n",
    "# Save model summary\n",
    "(OUT_MOD / \"rq2_logit_summary.txt\").write_text(str(logit_res.summary()))\n",
    "\n",
    "print(\"\\n[done] Outputs saved to ./outputs/{figures,tables,models}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
